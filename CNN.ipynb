{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan direktori utama dataset\n",
    "#dataset ini upload terlebih dulu ke drive agar bisa di load di google colab, \n",
    "#atau kalian bisa langsung download lewat kaggle langsung di google colab\n",
    "\n",
    "import os\n",
    "base_dir = '//PRAK.PCD TKK//OBINCNN//flowers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 53] The network path was not found: '//PRAK.PCD TKK//OBINCNN//flowers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(base_dir))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 53] The network path was not found: '//PRAK.PCD TKK//OBINCNN//flowers'"
     ]
    }
   ],
   "source": [
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah gambar pada dataset\n",
    "number_label = {}\n",
    "total_files = 0\n",
    "for i in os.listdir(base_dir):\n",
    "    counting = len(os.listdir(os.path.join(base_dir, i)))\n",
    "    number_label[i] = counting\n",
    "    total_files += counting\n",
    "\n",
    "print(\"Total Files : \" + str(total_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Visualisasi jumlah gambar tiap kelas\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mbar(number_label\u001b[39m.\u001b[39mkeys(), number_label\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mJumlah Gambar Tiap Label\u001b[39m\u001b[39m\"\u001b[39m);\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'number_label' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualisasi jumlah gambar tiap kelas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(number_label.keys(), number_label.values())\n",
    "plt.title(\"Jumlah Gambar Tiap Label\");\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Jumlah Gambar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan sampel gambar tiap kelas\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img_each_class = 1\n",
    "img_samples = {}\n",
    "classes = list(number_label.keys())\n",
    "\n",
    "\n",
    "for c in classes:\n",
    "    temp = os.listdir(os.path.join(base_dir, c))[:img_each_class]\n",
    "    for item in temp:\n",
    "        img_path = os.path.join(base_dir, c, item)\n",
    "        img_samples[c] = img_path\n",
    "\n",
    "for i in img_samples:\n",
    "    fig = plt.gcf()\n",
    "    img = mpimg.imread(img_samples[i])\n",
    "    plt.title(i)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (200,200)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan ImageDataGenerator untuk preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyiapkan data train dan data validation\n",
    "train_data = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_data = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(IMAGE_SIZE[0],\n",
    "                                  IMAGE_SIZE[1],\n",
    "                                  3)),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.Rescaling(1./255)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat arsitektur model CNN\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "  data_augmentation,\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling model\n",
    "cnn_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model CNN\n",
    "cnn_hist = cnn_model.fit(\n",
    "    train_data,\n",
    "    epochs=20,\n",
    "    validation_data = valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat plot akurasi model CNN\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(cnn_hist.history['accuracy'])\n",
    "plt.plot(cnn_hist.history['val_accuracy'])\n",
    "plt.title('CNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# Membuat plot loss model CNN\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(cnn_hist.history['loss'])\n",
    "plt.plot(cnn_hist.history['val_loss'])\n",
    "plt.title('CNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_vgg_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "base_vgg_model.trainable = False\n",
    "\n",
    "# Preprocessing Input\n",
    "vgg_preprocess = tf.keras.applications.vgg16.preprocess_input\n",
    "train_data.preprocessing_function = vgg_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning dengan VGG16\n",
    "vgg_model = tf.keras.models.Sequential([\n",
    "  data_augmentation,\n",
    "  base_vgg_model,\n",
    "  tf.keras.layers.Dropout(0.7),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling model\n",
    "vgg_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model VGG16\n",
    "vgg_hist = vgg_model.fit(\n",
    "    train_data,\n",
    "    epochs=20,\n",
    "    validation_data = valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat plot akurasi model VGG16\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(vgg_hist.history['accuracy'])\n",
    "plt.plot(vgg_hist.history['val_accuracy'])\n",
    "plt.title('VGG16 model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# Membuat plot loss model VGG16\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(vgg_hist.history['loss'])\n",
    "plt.plot(vgg_hist.history['val_loss'])\n",
    "plt.title('VGG16 model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Loading ResNet50 model\n",
    "base_resnet_model = ResNet50(include_top=False,\n",
    "                   input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3),\n",
    "                   pooling='max',classes=5,\n",
    "                   weights='imagenet')\n",
    "\n",
    "base_resnet_model.trainable = False\n",
    "\n",
    "train_data.preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "\n",
    "# Transfer learning ResNet50\n",
    "resnet_model = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    base_resnet_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "resnet_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model ResNet50\n",
    "resnet_hist = resnet_model.fit(\n",
    "    train_data,\n",
    "    epochs=20,\n",
    "    validation_data = valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat plot akurasi model ResNet50\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(resnet_hist.history['accuracy'])\n",
    "plt.plot(resnet_hist.history['val_accuracy'])\n",
    "plt.title('ResNet50 model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# Membuat plot loss model ResNet50\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(resnet_hist.history['loss'])\n",
    "plt.plot(resnet_hist.history['val_loss'])\n",
    "plt.title('ResNet50 model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading DenseNet201 model\n",
    "base_densenet_model = tf.keras.applications.DenseNet201(include_top=False,\n",
    "                                                        weights='imagenet',\n",
    "                                                        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
    "                                                        pooling='max')\n",
    "base_densenet_model.trainable=False\n",
    "train_data.preprocessing_function = tf.keras.applications.densenet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning DenseNet201\n",
    "densenet_model = tf.keras.models.Sequential([\n",
    "  data_augmentation,\n",
    "  base_densenet_model,\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling model\n",
    "densenet_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model DenseNet201\n",
    "densenet_hist = densenet_model.fit(\n",
    "    train_data,\n",
    "    epochs=20,\n",
    "    validation_data = valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat plot akurasi model DenseNet201\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(densenet_hist.history['accuracy'])\n",
    "plt.plot(densenet_hist.history['val_accuracy'])\n",
    "plt.title('DenseNet201 model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# Membuat plot loss model DenseNet201\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(densenet_hist.history['loss'])\n",
    "plt.plot(densenet_hist.history['val_loss'])\n",
    "plt.title('DenseNet201 model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat plot akurasi empat model sebelumnya untuk dibandingkan\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(cnn_hist.history['val_accuracy'])\n",
    "plt.plot(vgg_hist.history['val_accuracy'])\n",
    "plt.plot(resnet_hist.history['val_accuracy'])\n",
    "plt.plot(densenet_hist.history['val_accuracy'])\n",
    "plt.title('model validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['CNN', 'VGG16', 'ResNet50', 'DenseNet201'], loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan daftar kelas atau label gambar\n",
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menguji coba model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from google.colab import files\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#file upload, kode di bawah in hanya bisa dijalankan di google colab dengan mengimport from google.colab import files. Silahkan kalian ganti kodingannya agar bisa upload di jupyter notebook masing-masing \n",
    "#atau kalian langsung import file gambarnya langsung\n",
    "uploaded = files.upload()\n",
    " \n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # prediksi gambar\n",
    "  path = fn\n",
    "  img = image.load_img(path, target_size=IMAGE_SIZE)\n",
    "  imgplot = plt.imshow(img)\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    " \n",
    "  images = np.vstack([x])\n",
    "  classes = densenet_model.predict(images, batch_size=BATCH_SIZE)\n",
    "  classes = np.argmax(classes)\n",
    "  \n",
    "  print(fn)\n",
    "  if classes==0:\n",
    "    print('daisy')\n",
    "  elif classes==1:\n",
    "    print('dandelion')\n",
    "  elif classes==2:\n",
    "    print('rose')\n",
    "  elif classes==3:\n",
    "    print('sunflower')\n",
    "  else:\n",
    "    print('tulip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.save('model-flowers-recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(densenet_model)\n",
    "tflite_model = converter.convert()\n",
    "with tf.io.gfile.GFile('model-flowers-recognition.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
